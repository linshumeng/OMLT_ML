{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHTSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import pyomo.environ as pe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27588638\n",
      "65.523\n",
      "1.0\n",
      "250.0\n"
     ]
    }
   ],
   "source": [
    "# Read the data from the csv file\n",
    "data = np.genfromtxt('data/PHTSV_Table_HMAX_Adjusted.csv', delimiter=',')\n",
    "data = data[1:, :]\n",
    "\n",
    "# 2 D array containing Pressure and Enthalpy data\n",
    "P_H = data[:, 0:2]\n",
    "\n",
    "# Scale the pressure to bar and scale the enthalpy to kJ/mol\n",
    "P_H[:, 0] = P_H[:, 0] / 1e5\n",
    "P_H[:, 1] = P_H[:, 1] / 1000\n",
    "minP = np.min(data[:, 0])\n",
    "maxP = np.max(data[:, 0])\n",
    "minH = np.min(data[:, 1])\n",
    "maxH = np.max(data[:, 1])\n",
    "print(minH)\n",
    "print(maxH)\n",
    "print(minP)\n",
    "print(maxP)\n",
    "\n",
    "# Vector containing Temperatures\n",
    "T = data[:, 2]\n",
    "minT = np.min(T)\n",
    "maxT = np.max(T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    P_H, T, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost: 0.04886913299560547 s\n",
      "Linear trees error: 46.104\n",
      "numer of leaves: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shumengl\\.conda\\envs\\omlt_lt\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "lgb_dic = {}\n",
    "train_data_linear = lgb.Dataset(\n",
    "    X_train, label=y_train)\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.4,\n",
    "    'num_leaves': 20,\n",
    "    \"verbosity\": -1,\n",
    "    'min_samples_leaf': 8,\n",
    "    'max_bin': 60,\n",
    "    'num_iterations': 10,\n",
    "    'max_depth': 10,\n",
    "}\n",
    "time_start = time.time()\n",
    "model_linear = lgb.train(params, train_data_linear)\n",
    "time_end = time.time()\n",
    "print('time cost:', time_end - time_start, 's')\n",
    "y_pred_linear = model_linear.predict(X_test)\n",
    "print(\n",
    "    f\"Linear trees error: {round(mean_squared_error(y_test, y_pred_linear),3)}\")\n",
    "df = model_linear.trees_to_dataframe()\n",
    "# len(df[df[\"right_child\"].isnull()]) == len(\n",
    "#     df[df[\"left_child\"].isnull()]) == len(df[df[\"decision_type\"].isnull()])\n",
    "print('numer of leaves:', len(df[df[\"right_child\"].isnull()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxmltools.convert.lightgbm.convert import convert\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "lgb_model = model_linear\n",
    "float_tensor_type = FloatTensorType([None, lgb_model.num_feature()])\n",
    "initial_types = [('float_input', float_tensor_type)]\n",
    "onnx_model = convert(lgb_model,\n",
    "                     initial_types=initial_types,\n",
    "                     target_opset=8)\n",
    "\n",
    "graph = onnx_model.graph\n",
    "\n",
    "# graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float_input: ?, 2, "
     ]
    }
   ],
   "source": [
    "# iterate through inputs of the graph\n",
    "for input in graph.input:\n",
    "    print(input.name, end=\": \")\n",
    "    # get type of input tensor\n",
    "    tensor_type = input.type.tensor_type\n",
    "    # check if it has a shape:\n",
    "    if (tensor_type.HasField(\"shape\")):\n",
    "        # iterate through dimensions of the shape:\n",
    "        for d in tensor_type.shape.dim:\n",
    "            # the dimension may have a definite (integer) value or a symbolic identifier or neither:\n",
    "            if (d.HasField(\"dim_value\")):\n",
    "                n_input = d.dim_value\n",
    "                print(d.dim_value, end=\", \")  # known dimension\n",
    "            elif (d.HasField(\"dim_param\")):\n",
    "                # unknown dimension with symbolic name\n",
    "                print(d.dim_param, end=\", \")\n",
    "            else:\n",
    "                print(\"?\", end=\", \")  # unknown dimension with no name\n",
    "    else:\n",
    "        print(\"unknown rank\", end=\"\")\n",
    "\n",
    "# print(n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _node_attributes(node):\n",
    "    attr = dict()\n",
    "    for at in node.attribute:\n",
    "        attr[at.name] = at\n",
    "    return attr\n",
    "\n",
    "root_node = graph.node[0]\n",
    "attr = _node_attributes(root_node)\n",
    "\n",
    "# attr\n",
    "base_value = (\n",
    "    np.array(attr[\"base_values\"].floats)[\n",
    "        0] if \"base_values\" in attr else 0.0\n",
    ")\n",
    "\n",
    "# default left true\n",
    "nodes_feature_ids = np.array(attr[\"nodes_featureids\"].ints)\n",
    "nodes_values = np.array(attr[\"nodes_values\"].floats)\n",
    "nodes_modes = np.array(attr[\"nodes_modes\"].strings)\n",
    "nodes_tree_ids = np.array(attr[\"nodes_treeids\"].ints)\n",
    "nodes_node_ids = np.array(attr[\"nodes_nodeids\"].ints)\n",
    "nodes_false_node_ids = np.array(attr[\"nodes_falsenodeids\"].ints)\n",
    "nodes_true_node_ids = np.array(attr[\"nodes_truenodeids\"].ints)\n",
    "\n",
    "n_targets = attr[\"n_targets\"].i  # assert is 1 or not\n",
    "target_ids = np.array(attr[\"target_ids\"].ints)  # assert is same or not\n",
    "target_node_ids = np.array(attr[\"target_nodeids\"].ints)\n",
    "target_tree_ids = np.array(attr[\"target_treeids\"].ints)\n",
    "target_weights = np.array(attr[\"target_weights\"].floats)\n",
    "\n",
    "nodes_leaf_mask = nodes_modes == b\"LEAF\"\n",
    "nodes_branch_mask = nodes_modes == b\"BRANCH_LEQ\"\n",
    "\n",
    "tree_ids = set(nodes_tree_ids)\n",
    "feature_ids = set(nodes_feature_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import deque\n",
    "\n",
    "splits_dic = defaultdict(dict)\n",
    "leaves_dic = defaultdict(dict)\n",
    "for i in tree_ids:\n",
    "    # splits_dic[i] = {\"node\": nodes_node_ids[nodes_tree_ids==i]}\n",
    "    node = nodes_node_ids[nodes_tree_ids==i]\n",
    "    feature = nodes_feature_ids[nodes_tree_ids==i]\n",
    "    value = nodes_values[nodes_tree_ids == i]\n",
    "    mode = nodes_modes[nodes_tree_ids == i]\n",
    "    target_weight = target_weights[target_tree_ids == i]\n",
    "    count = 0\n",
    "    count_leaf = 0\n",
    "    queue = deque([node[count]])\n",
    "    while queue:\n",
    "        cur = queue[0]\n",
    "        queue.popleft()\n",
    "        # print(cur, mode[cur])\n",
    "        if mode[cur] == b'BRANCH_LEQ':\n",
    "            splits_dic[i][cur] = {'th': value[cur],\n",
    "                                'col': feature[cur],\n",
    "                                'children': [None, None]}\n",
    "            queue.appendleft(node[count + 2])\n",
    "            splits_dic[i][cur]['children'][0] = node[count+1]\n",
    "            queue.appendleft(node[count + 1])\n",
    "            splits_dic[i][cur]['children'][1] = node[count+2]\n",
    "            count += 2\n",
    "        else:\n",
    "            # print(cur, i, count_leaf, target_weight[count_leaf])\n",
    "            leaves_dic[i][cur] = {'val': target_weight[count_leaf]}\n",
    "            count_leaf += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_leaves(input_node, t):\n",
    "    root_node = input_node\n",
    "    leaves_list = []\n",
    "    queue = [root_node]\n",
    "    while queue:\n",
    "        node = queue.pop()\n",
    "        node_left = node['children'][0]\n",
    "        node_right = node['children'][1]\n",
    "        if node_left in leaves_dic[t]:\n",
    "            leaves_list.append(node_left)\n",
    "        else:\n",
    "            queue.append(splits_dic[t][node_left])\n",
    "        if node_right in leaves_dic[t]:\n",
    "            leaves_list.append(node_right)\n",
    "        else:\n",
    "            queue.append(splits_dic[t][node_right])\n",
    "    return leaves_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tree_ids:\n",
    "    for s in splits_dic[t].keys():\n",
    "        # print(t, s)\n",
    "        cur_node = splits_dic[t][s]\n",
    "        # print(cur_node)\n",
    "        cur_node_left = cur_node['children'][0]\n",
    "        cur_node_right = cur_node['children'][1]\n",
    "        cur_node['left_leaves'], cur_node['right_leaves'] = [], []\n",
    "        if cur_node_left in leaves_dic[t]:\n",
    "            cur_node['left_leaves'].append(cur_node_left)\n",
    "        else:\n",
    "            cur_node['left_leaves'] = find_leaves(splits_dic[t][cur_node_left], t)\n",
    "        if cur_node_right in leaves_dic[t]:\n",
    "            cur_node['right_leaves'].append(cur_node_right)\n",
    "        else:\n",
    "            cur_node['right_leaves'] = find_leaves(splits_dic[t][cur_node_right], t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\Program Files\\Graphviz\\\\bin'\n",
    "# lgb.plot_tree(model_linear)\n",
    "# for i in range(params['num_iterations']):\n",
    "# p = lgb.create_tree_digraph(model_linear, params['num_iterations'] - 1)\n",
    "p = lgb.create_tree_digraph(model_linear, -1)\n",
    "# p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tree_ids:\n",
    "#     splits = splits_dic[i]\n",
    "#     leaves = leaves_dic[i]\n",
    "#     for split in splits:\n",
    "#         left_child = splits[split]['children'][0]\n",
    "#         right_child = splits[split]['children'][1]\n",
    "#         if left_child in splits:\n",
    "#             splits[left_child]['parent'] = split\n",
    "#         else:\n",
    "#             leaves[left_child]['parent'] = split\n",
    "\n",
    "#         if right_child in splits:\n",
    "#             splits[right_child]['parent'] = split\n",
    "#         else:\n",
    "#             leaves[right_child]['parent'] = split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_all_children_splits(split, splits_dict):\n",
    "#     \"\"\"\n",
    "#     This helper function finds all multigeneration children splits for an \n",
    "#     argument split.\n",
    "\n",
    "#     Arguments:\n",
    "#         split --The split for which you are trying to find children splits\n",
    "#         splits_dict -- A dictionary of all the splits in the tree\n",
    "\n",
    "#     Returns:\n",
    "#         A list containing the Node IDs of all children splits\n",
    "#     \"\"\"\n",
    "#     all_splits = []\n",
    "\n",
    "#     # Check if the immediate left child of the argument split is also a split.\n",
    "#     # If so append to the list then use recursion to generate the remainder\n",
    "#     left_child = splits_dict[split]['children'][0]\n",
    "#     if left_child in splits_dict:\n",
    "#         all_splits.append(left_child)\n",
    "#         all_splits.extend(find_all_children_splits(left_child, splits_dict))\n",
    "\n",
    "#     # Same as above but with right child\n",
    "#     right_child = splits_dict[split]['children'][1]\n",
    "#     if right_child in splits_dict:\n",
    "#         all_splits.append(right_child)\n",
    "#         all_splits.extend(find_all_children_splits(right_child, splits_dict))\n",
    "\n",
    "#     return all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_all_children_leaves(split, splits_dict, leaves_dict):\n",
    "#     \"\"\"\n",
    "#     This helper function finds all multigeneration children leaves for an \n",
    "#     argument split.\n",
    "\n",
    "#     Arguments:\n",
    "#         split -- The split for which you are trying to find children leaves\n",
    "#         splits_dict -- A dictionary of all the split info in the tree\n",
    "#         leaves_dict -- A dictionary of all the leaf info in the tree\n",
    "\n",
    "#     Returns:\n",
    "#         A list containing all the Node IDs of all children leaves\n",
    "#     \"\"\"\n",
    "#     all_leaves = []\n",
    "\n",
    "#     # Find all the splits that are children of the relevant split\n",
    "#     all_splits = find_all_children_splits(split, splits_dict)\n",
    "\n",
    "#     # Ensure the current split is included\n",
    "#     if split not in all_splits:\n",
    "#         all_splits.append(split)\n",
    "\n",
    "#     # For each leaf, check if the parents appear in the list of children\n",
    "#     # splits (all_splits). If so, it must be a leaf of the argument split\n",
    "#     for leaf in leaves_dict:\n",
    "#         if leaves_dict[leaf]['parent'] in all_splits:\n",
    "#             all_leaves.append(leaf)\n",
    "\n",
    "#     return all_leaves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tree_ids:\n",
    "#     splits = splits_dic[i]\n",
    "#     leaves = leaves_dic[i]\n",
    "#     for split in splits:\n",
    "#         # print(\"split:\" + str(split))\n",
    "#         left_child = splits[split]['children'][0]\n",
    "#         right_child = splits[split]['children'][1]\n",
    "\n",
    "#         if left_child in splits:\n",
    "#             # means left_child is split\n",
    "#             splits[split]['left_leaves'] = find_all_children_leaves(\n",
    "#                 left_child, splits, leaves\n",
    "#             )\n",
    "#         else:\n",
    "#             # means left_child is leaf\n",
    "#             splits[split]['left_leaves'] = [left_child]\n",
    "#             # print(\"left_child\" + str(left_child))\n",
    "\n",
    "#         if right_child in splits:\n",
    "#             splits[split]['right_leaves'] = find_all_children_leaves(\n",
    "#                 right_child, splits, leaves\n",
    "#             )\n",
    "#         else:\n",
    "#             splits[split]['right_leaves'] = [right_child]\n",
    "#             # print(\"right_child\" + str(right_child))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.arange(0, n_input) # take care of this features, it is only the # of features in a tree not for all\n",
    "for i in tree_ids:\n",
    "    splits = splits_dic[i]\n",
    "    leaves = leaves_dic[i]\n",
    "    for leaf in leaves:\n",
    "        leaves[leaf]['bounds'] = {}\n",
    "    for th in features:\n",
    "        for leaf in leaves:\n",
    "            leaves[leaf]['bounds'][th] = [None, None]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tree_ids:\n",
    "    splits = splits_dic[i]\n",
    "    leaves = leaves_dic[i]\n",
    "    for split in splits:\n",
    "        var = splits[split]['col']\n",
    "        for leaf in splits[split]['left_leaves']:\n",
    "            leaves[leaf]['bounds'][var][1] = splits[split]['th']\n",
    "\n",
    "        for leaf in splits[split]['right_leaves']:\n",
    "            leaves[leaf]['bounds'][var][0] = splits[split]['th']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_none_bounds(leaves, input_bounds):\n",
    "    \"\"\"\n",
    "    This helper function reassigns bounds that are None to the bounds\n",
    "    input by the user\n",
    "\n",
    "    Arguments:\n",
    "        leaves -- The dictionary of leaf information. Attribute of the \n",
    "            LinearTreeModel object\n",
    "        input_bounds -- The nested dictionary\n",
    "\n",
    "    Returns:\n",
    "        The modified leaves dict without any bounds that are listed as None\n",
    "    \"\"\"\n",
    "    L = np.array(list(leaves.keys()))\n",
    "    features = np.arange(0,len(set(nodes_feature_ids)))\n",
    "\n",
    "    for l in L:\n",
    "        for f in features:\n",
    "            if leaves[l]['bounds'][f][0] == None:\n",
    "                leaves[l]['bounds'][f][0] = input_bounds[f][0]\n",
    "            if leaves[l]['bounds'][f][1] == None:\n",
    "                leaves[l]['bounds'][f][1] = input_bounds[f][1]\n",
    "\n",
    "    return leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "minP = np.min(data[:, 0])\n",
    "maxP = np.max(data[:, 0])\n",
    "minH = np.min(data[:, 1])\n",
    "maxH = np.max(data[:, 1])\n",
    "stdP = np.std(data[:, 0])\n",
    "stdH = np.std(data[:, 1])\n",
    "meanP = np.mean(data[:, 0])\n",
    "meanH = np.mean(data[:, 1])\n",
    "\n",
    "input_bounds = {0: (minP, maxP), \n",
    "                1: (minH, maxH)}\n",
    "input_bounds\n",
    "\n",
    "for t in tree_ids:\n",
    "    leaves_dic[t] = reassign_none_bounds(leaves_dic[t], input_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaves = reassign_none_bounds(leaves, input_bounds)\n",
    "# import pprint\n",
    "# pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# pp.pprint(leaves_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Constant objective detected, replacing with a placeholder to prevent\n",
      "    solver failure.\n",
      "[443.30954921] 443.30956568568945\n"
     ]
    }
   ],
   "source": [
    "m = pe.ConcreteModel()\n",
    "m.T = pe.Var()\n",
    "m.P = pe.Var()\n",
    "m.H = pe.Var()\n",
    "\n",
    "def create_tree_block(leaves_dic):\n",
    "    b = pe.Block(concrete=True)\n",
    "\n",
    "    tree_leaf_set = []\n",
    "    for t in tree_ids:\n",
    "        for l in leaves_dic[t].keys():\n",
    "            tree_leaf_set.append((t, l))\n",
    "\n",
    "    b.z = pe.Var(tree_leaf_set, within=pe.Binary)\n",
    "    b.d = pe.Var(tree_ids)\n",
    "    # b.z.pprint()\n",
    "\n",
    "    # print(tf_set)\n",
    "    b.P_H = pe.Var(features, within=pe.NonNegativeReals)\n",
    "    # b.P_H.pprint()\n",
    "    b.T = pe.Var(within=pe.NonNegativeReals)\n",
    "\n",
    "    def lowerBounds(m, t, f):\n",
    "        # t = 1\n",
    "        leaves = leaves_dic[t]\n",
    "        L = np.array(list(leaves.keys()))\n",
    "        return sum(leaves_dic[t][l]['bounds'][f][0] * m.z[t, l] for l in L) <= m.P_H[f]\n",
    "\n",
    "\n",
    "    b.lbCon = pe.Constraint(tree_ids, features, rule=lowerBounds)\n",
    "\n",
    "\n",
    "    def upperBounds(m, t, f):\n",
    "        leaves = leaves_dic[t]\n",
    "        L = np.array(list(leaves.keys()))\n",
    "        return sum(leaves_dic[t][l]['bounds'][f][1] * m.z[t, l] for l in L) >= m.P_H[f]\n",
    "    b.ubCon = pe.Constraint(tree_ids, features, rule=upperBounds)\n",
    "\n",
    "    def outPuts(m, t):\n",
    "        leaves = leaves_dic[t]\n",
    "        L = np.array(list(leaves.keys()))\n",
    "        return sum(m.z[t, l] * leaves_dic[t][l]['val'] for l in L) == b.d[t]\n",
    "    b.outputCon = pe.Constraint(tree_ids, rule=outPuts)\n",
    "\n",
    "    def onlyOne(m, t):\n",
    "        leaves = leaves_dic[t]\n",
    "        L = np.array(list(leaves.keys()))\n",
    "        return sum(b.z[t, l] for l in L) == 1\n",
    "    b.onlyOneCon = pe.Constraint(tree_ids, rule=onlyOne)\n",
    "\n",
    "    b.final_sum = pe.Constraint(expr = b.T == sum(b.d[t] for t in tree_ids))\n",
    "\n",
    "    return b\n",
    "\n",
    "m.tree_model = create_tree_block(leaves_dic)\n",
    "\n",
    "m.linkP = pe.Constraint(expr = m.P == m.tree_model.P_H[0])\n",
    "m.linkH = pe.Constraint(expr=m.H == m.tree_model.P_H[1])\n",
    "m.linkT = pe.Constraint(expr = m.T == m.tree_model.T)\n",
    "\n",
    "m.P.fix(5)\n",
    "m.H.fix(50)\n",
    "\n",
    "m.obj = pe.Objective(expr=1)\n",
    "\n",
    "solver = pe.SolverFactory('gurobi')\n",
    "results = solver.solve(m)\n",
    "\n",
    "out = model_linear.predict(np.array([5, 50]).reshape(1,-1))\n",
    "print(out, pe.value(m.T))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omlt_lt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95ce0754aa414e43087b3240e2c924850753614786f844f4102022f54760296e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
